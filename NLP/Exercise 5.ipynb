{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW5_2021 (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be73d2f4c8204fe8b29606419b0c9207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e3305090792a480193b47f3f0c57edb5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2bdde1a7dced41af861374dc6cd73b51",
              "IPY_MODEL_cf49baaee78747c7b233533c4913f849"
            ]
          }
        },
        "e3305090792a480193b47f3f0c57edb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2bdde1a7dced41af861374dc6cd73b51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_462ff2b30a3a4d59a6a7cd67078afe61",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 20,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 20,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cb07c5506e4402fb45a97bd41019232"
          }
        },
        "cf49baaee78747c7b233533c4913f849": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5b674881e114d94ba7b11859c4feedc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 20/20 [1:32:19&lt;00:00, 276.98s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ab85d09ee4c444ab0298172eab3523a"
          }
        },
        "462ff2b30a3a4d59a6a7cd67078afe61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cb07c5506e4402fb45a97bd41019232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5b674881e114d94ba7b11859c4feedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ab85d09ee4c444ab0298172eab3523a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c7c104d0a7c49be915505a59402edaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9adb5f40b8dd43d3b3484796e99aaa65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f5110458a36d4f5a9344114022180c62",
              "IPY_MODEL_f2784386c37444bdb89592b9d44a5327"
            ]
          }
        },
        "9adb5f40b8dd43d3b3484796e99aaa65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f5110458a36d4f5a9344114022180c62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b39bcf25402f452f9a6f77624067e7bf",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c3921a74257b47f389df4fdcdf04ce78"
          }
        },
        "f2784386c37444bdb89592b9d44a5327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f532e20dd8c94d49bc8b66ded47de181",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [1:32:10&lt;00:00, 1106.15s/ba]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_67614bce80b3434ebafe568a19c281ae"
          }
        },
        "b39bcf25402f452f9a6f77624067e7bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c3921a74257b47f389df4fdcdf04ce78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f532e20dd8c94d49bc8b66ded47de181": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "67614bce80b3434ebafe568a19c281ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhOUh0qzFFje"
      },
      "source": [
        "\n",
        "\n",
        "In this exercise, we are going to fine-tune a model on a supervised **relation extraction** dataset.\n",
        "\n",
        "The goal of the model is to predict, given a sentence and the character spans of two entities within the sentence, the relationship between the entities.\n",
        "\n",
        "For example given the sentence:\n",
        "\n",
        "\n",
        "**John, who played last night, is Doe's father.**\n",
        "\n",
        "\n",
        "The model given the sentence and the spans of the entities John a Doe the model will have to predict what is the relation between Dohn and Doe from a set of pre-defined relations in this case the relation is parents (please note that some of the relations are one-way relations)\n",
        "\n",
        "The dataset we will use is a subset of the [TACRED](https://nlp.stanford.edu/projects/tacred/) dataset, a supervised relation extraction dataset by Stanford University. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFLhifPY8V58"
      },
      "source": [
        "As you realize by now, the straight forward supervised approach is just to take one of the transformers and use the sentence and the entity spans as input. However, in this exercise we will try a different approach using **Question Answering (QA)**.\n",
        "\n",
        "Instead of just using the entities span and the sentence, we will train a model to answer the following questions \"Who are the parents of John?\",\"Who are the children of Doe?\". If the question answering model will be able to answer the question succusfully than we will be able to conclude that the relation between the two entites exists.\n",
        "\n",
        "In general **for each realtion** we will need to come up with template questions: In the example above the template questions corresponding to the parents relation are: \n",
        "\n",
        "*   Who are the parents of E1?\n",
        "*   Who are the children of E2?\n",
        "\n",
        "where E1 and E2 are the entities.\n",
        "\n",
        "\n",
        "\n",
        "# Your part\n",
        "\n",
        "You are required to fine-tune a model for relation extraction using the question answering framework.\n",
        "\n",
        "Notes:\n",
        "\n",
        "\n",
        "* In previous lectures we have seen a demo notebook demonstrating how to fine-tune a transformer on SQUAD, **from a technical prespective we are doing the same.**\n",
        "*   For each one of the seven relations in the dataset you will need to find appropriate questions (please note that the questions must be SQUAD-like, meaning that if the answer exists it must be contained within the sentence in a contiguous way.)\n",
        "* There are several issues that you will need to consider. Please provide a brief explanation whenever you tackle such issues\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUE24XG63vPM"
      },
      "source": [
        "## Data\n",
        "\n",
        "Let's download the data from the web, hosted on Dropbox."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sFqwmObswh9"
      },
      "source": [
        "!pip install -q transformers "
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeKagbUCNj05"
      },
      "source": [
        "import requests, zipfile, io\n",
        "\n",
        "def download_data():\n",
        "    url = \"https://www.dropbox.com/s/izi2x4sjohpzoot/relation_extraction_dataset.zip?dl=1\"\n",
        "    r = requests.get(url)\n",
        "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
        "    z.extractall()\n",
        "\n",
        "download_data()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TG7bi0fYOfw2"
      },
      "source": [
        "Each row in the dataframe consists of a news article, and a sentence in which a certain relationship was found (just as \"invested_in\", or \"founded_by\"). There were some patterns used to gather the data, so it might contain some noise. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hDkptorP9Koh",
        "outputId": "3ff1d8e9-a85e-4ace-dcee-62cedcfa9332"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_pickle(\"relation_extraction_dataset.pkl\")\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>end_idx</th>\n",
              "      <th>entities</th>\n",
              "      <th>entity_spans</th>\n",
              "      <th>match</th>\n",
              "      <th>original_article</th>\n",
              "      <th>sentence</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>string_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1024</td>\n",
              "      <td>[Lilium, Baillie Gifford]</td>\n",
              "      <td>[[3, 9], [151, 166]]</td>\n",
              "      <td>raising $35</td>\n",
              "      <td>Happy Friday!\\n\\nWe sincerely hope you and you...</td>\n",
              "      <td>3) Lilium, a German startup thatâ€™s making an a...</td>\n",
              "      <td>1013</td>\n",
              "      <td>invested_in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1762</td>\n",
              "      <td>[Facebook â€™s, Giphy]</td>\n",
              "      <td>[[92, 102], [148, 153]]</td>\n",
              "      <td>acquisition</td>\n",
              "      <td>Happy Friday!\\n\\nWe sincerely hope you and you...</td>\n",
              "      <td>Meanwhile, the UKâ€™s watchdog on Friday announc...</td>\n",
              "      <td>1751</td>\n",
              "      <td>acquired_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2784</td>\n",
              "      <td>[Global-e, Vitruvian Partners]</td>\n",
              "      <td>[[27, 35], [94, 112]]</td>\n",
              "      <td>raised $60</td>\n",
              "      <td>Happy Friday!\\n\\nWe sincerely hope you and you...</td>\n",
              "      <td>Israeli e-commerce startup Global-e has raised...</td>\n",
              "      <td>2774</td>\n",
              "      <td>invested_in</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>680</td>\n",
              "      <td>[Joris Van Der Gucht, Silverfin]</td>\n",
              "      <td>[[0, 19], [35, 44]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Hg is a leading investor in tax and accounting...</td>\n",
              "      <td>Joris Van Der Gucht, co-founder at Silverfin c...</td>\n",
              "      <td>673</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2070</td>\n",
              "      <td>[Tim Vandecasteele, Silverfin]</td>\n",
              "      <td>[[0, 17], [71, 80]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Hg is a leading investor in tax and accounting...</td>\n",
              "      <td>Tim Vandecasteele, co-founder added: \"We want ...</td>\n",
              "      <td>2063</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  end_idx                          entities  ... start_idx    string_id\n",
              "0    1024         [Lilium, Baillie Gifford]  ...      1013  invested_in\n",
              "1    1762              [Facebook â€™s, Giphy]  ...      1751  acquired_by\n",
              "2    2784    [Global-e, Vitruvian Partners]  ...      2774  invested_in\n",
              "3     680  [Joris Van Der Gucht, Silverfin]  ...       673   founded_by\n",
              "4    2070    [Tim Vandecasteele, Silverfin]  ...      2063   founded_by\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOQ0StVfOEw0"
      },
      "source": [
        "Let's create 2 dictionaries, one that maps each label to a unique integer, and one that does it the other way around."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDTHyKq2A8-d"
      },
      "source": [
        "id2label = dict()\n",
        "for idx, label in enumerate(df.string_id.value_counts().index):\n",
        "  id2label[idx] = label"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIv9xV_eOthR"
      },
      "source": [
        "As we can see, there are 7 labels (7 unique relationships):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhnbVGAZBW4B",
        "outputId": "cbb7e1cb-dc69-4588-dbee-382f76ddb1ce"
      },
      "source": [
        "id2label"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'founded_by',\n",
              " 1: 'acquired_by',\n",
              " 2: 'invested_in',\n",
              " 3: 'CEO_of',\n",
              " 4: 'subsidiary_of',\n",
              " 5: 'partners_with',\n",
              " 6: 'owned_by'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ecDeeGVBYDM",
        "outputId": "61ab2a1b-68b4-42e1-9754-4dc0c15a7ef4"
      },
      "source": [
        "label2id = {v:k for k,v in id2label.items()}\n",
        "label2id"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CEO_of': 3,\n",
              " 'acquired_by': 1,\n",
              " 'founded_by': 0,\n",
              " 'invested_in': 2,\n",
              " 'owned_by': 6,\n",
              " 'partners_with': 5,\n",
              " 'subsidiary_of': 4}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgKl-ZVcANUb"
      },
      "source": [
        "## Good Luck\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isfZesWqjCj5"
      },
      "source": [
        "model_checkpoint = \"distilbert-base-uncased\"\n",
        "batch_size = 16"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "4TymVjVJaVrD",
        "outputId": "25d99396-79cd-4866-84b4-6027a71879ff"
      },
      "source": [
        "df[df['string_id']=='founded_by'].sample(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>end_idx</th>\n",
              "      <th>entities</th>\n",
              "      <th>entity_spans</th>\n",
              "      <th>match</th>\n",
              "      <th>original_article</th>\n",
              "      <th>sentence</th>\n",
              "      <th>start_idx</th>\n",
              "      <th>string_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7643</th>\n",
              "      <td>6059</td>\n",
              "      <td>[Keleya, Demodesk]</td>\n",
              "      <td>[[10, 16], [161, 169]]</td>\n",
              "      <td>Founded</td>\n",
              "      <td>Germany has one of the most vital startup scen...</td>\n",
              "      <td>Apps like Keleya might benefit from that Demod...</td>\n",
              "      <td>6052</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8161</th>\n",
              "      <td>2463</td>\n",
              "      <td>[DoorDash, Tony Xu]</td>\n",
              "      <td>[[0, 8], [17, 24]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Feedzai: Feedzai is a San Mateo, Ca.-based dat...</td>\n",
              "      <td>DoorDash founder Tony Xu, StockX CEO Scott Cut...</td>\n",
              "      <td>2456</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7630</th>\n",
              "      <td>7366</td>\n",
              "      <td>[Henrik Torstensson, Lifesum]</td>\n",
              "      <td>[[0, 18], [139, 146]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>The land of Abba, Volvo, and Ikea is so much m...</td>\n",
              "      <td>Henrik Torstensson is a Swedish entrepreneur a...</td>\n",
              "      <td>7359</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1489</th>\n",
              "      <td>5202</td>\n",
              "      <td>[Elizabeth Varley, TechHub]</td>\n",
              "      <td>[[0, 16], [43, 50]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>With today being International Women's Day, we...</td>\n",
              "      <td>Elizabeth Varley is the founder and CEO of Tec...</td>\n",
              "      <td>5195</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8427</th>\n",
              "      <td>8531</td>\n",
              "      <td>[NFX, James Currier]</td>\n",
              "      <td>[[67, 70], [82, 95]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>2What s in a name More than two years ago Fast...</td>\n",
              "      <td>the name of your company is what gets passed b...</td>\n",
              "      <td>8524</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11300</th>\n",
              "      <td>3072</td>\n",
              "      <td>[Craig Rosenberg, TOPO]</td>\n",
              "      <td>[[122, 137], [171, 175]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Acquisition Strengthens #1 Sales Engagement Pl...</td>\n",
              "      <td>When we look across our dataset of high-growth...</td>\n",
              "      <td>3065</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6971</th>\n",
              "      <td>1346</td>\n",
              "      <td>[Konrad Feldman, Quantcast]</td>\n",
              "      <td>[[198, 212], [236, 245]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Powerful AI and Machine Learning Technology De...</td>\n",
              "      <td>\"As champions of a free and open internet, we ...</td>\n",
              "      <td>1339</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3085</th>\n",
              "      <td>1086</td>\n",
              "      <td>[Monerium, Sveinn Valfells]</td>\n",
              "      <td>[[15, 23], [43, 58]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>Licensed e money issuer Monerium will support ...</td>\n",
              "      <td>In a statement Monerium co founder and CEO Sve...</td>\n",
              "      <td>1079</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7046</th>\n",
              "      <td>4139</td>\n",
              "      <td>[Emma Best, Denial of Secrets]</td>\n",
              "      <td>[[169, 178], [206, 223]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>The report has sparked calls by lawmakers and ...</td>\n",
              "      <td>\"It contains pretty much everything on Gab, in...</td>\n",
              "      <td>4132</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7697</th>\n",
              "      <td>1426</td>\n",
              "      <td>[Saurabh Singh, Flickstree]</td>\n",
              "      <td>[[106, 119], [143, 153]]</td>\n",
              "      <td>founder</td>\n",
              "      <td>BENGALURU: Mumbai-based digital video curation...</td>\n",
              "      <td>, it also allows our publisher partners to ear...</td>\n",
              "      <td>1419</td>\n",
              "      <td>founded_by</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      end_idx                        entities  ... start_idx   string_id\n",
              "7643     6059              [Keleya, Demodesk]  ...      6052  founded_by\n",
              "8161     2463             [DoorDash, Tony Xu]  ...      2456  founded_by\n",
              "7630     7366   [Henrik Torstensson, Lifesum]  ...      7359  founded_by\n",
              "1489     5202     [Elizabeth Varley, TechHub]  ...      5195  founded_by\n",
              "8427     8531            [NFX, James Currier]  ...      8524  founded_by\n",
              "11300    3072         [Craig Rosenberg, TOPO]  ...      3065  founded_by\n",
              "6971     1346     [Konrad Feldman, Quantcast]  ...      1339  founded_by\n",
              "3085     1086     [Monerium, Sveinn Valfells]  ...      1079  founded_by\n",
              "7046     4139  [Emma Best, Denial of Secrets]  ...      4132  founded_by\n",
              "7697     1426     [Saurabh Singh, Flickstree]  ...      1419  founded_by\n",
              "\n",
              "[10 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW5Zrqu4J7bO"
      },
      "source": [
        "Creating the dataset:\n",
        "\n",
        "We choose the setence and not the entire article as the context and generate 2 questions for each row (one for each side of the relationship), doubling the number of rows.\n",
        "\n",
        "As was told in the office hour we always define thw relation direction as E1 relation E2, even though part of the data relations are in the opposite direction. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "KfrQJtYyn6rN",
        "outputId": "19b1ea67-acb7-4f9d-c74e-7c323b2a7f1a"
      },
      "source": [
        "pd.options.mode.chained_assignment = None  # default='warn'\n",
        "\n",
        "# Dataset with questions for founded_by relationship\n",
        "\n",
        "who_founded = df[df['string_id']=='founded_by']\n",
        "who_founded['answers'] = who_founded.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "who_founded['context'] = who_founded['sentence']\n",
        "who_founded['id'] = 'wf' + who_founded.index.map(str)\n",
        "who_founded['question'] = who_founded.apply(lambda row: 'Who founded ' + row.entities[0] + '?', axis = 1)\n",
        "who_founded['title'] = who_founded.apply(lambda row: row.entities[0] + ' founded by ' + row.entities[1], axis = 1)\n",
        "\n",
        "what_was_found = df[df['string_id']=='founded_by']\n",
        "what_was_found['answers'] = what_was_found.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "what_was_found['context'] = what_was_found['sentence']\n",
        "what_was_found['id'] = 'wwf' + what_was_found.index.map(str)\n",
        "what_was_found['question'] = what_was_found.apply(lambda row: 'What was founded by ' + row.entities[1] + '?', axis = 1)\n",
        "what_was_found['title'] = what_was_found.apply(lambda row: row.entities[0] + ' founded by ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [who_founded, what_was_found]\n",
        "founded_by = pd.concat(frames)\n",
        "founded_by.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "founded_by.sample(6)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>{'answer_start': [28], 'text': ['Wasowski Vent...</td>\n",
              "      <td>, Piotr is founder &amp; CEO of Wasowski Ventures,...</td>\n",
              "      <td>wf429</td>\n",
              "      <td>Who founded Piotr?</td>\n",
              "      <td>Piotr founded by Wasowski Ventures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1162</th>\n",
              "      <td>{'answer_start': [24], 'text': ['Finless Foods']}</td>\n",
              "      <td>In October, 28-year-old Finless Foods co-found...</td>\n",
              "      <td>wwf1162</td>\n",
              "      <td>What was founded by Mike Selden?</td>\n",
              "      <td>Finless Foods founded by Mike Selden</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1808</th>\n",
              "      <td>{'answer_start': [17], 'text': ['Charlie Lee']}</td>\n",
              "      <td>Litecoin founder Charlie Lee and Ethereum co-f...</td>\n",
              "      <td>wf1808</td>\n",
              "      <td>Who founded Litecoin?</td>\n",
              "      <td>Litecoin founded by Charlie Lee</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>{'answer_start': [52], 'text': ['cleantech Hol...</td>\n",
              "      <td>Carlota PiÂ is co-founder and Executive Preside...</td>\n",
              "      <td>wf1451</td>\n",
              "      <td>Who founded Carlota Pi?</td>\n",
              "      <td>Carlota Pi founded by cleantech Holaluz</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3362</th>\n",
              "      <td>{'answer_start': [295], 'text': ['WhizHack Tec...</td>\n",
              "      <td>Private Limited signed an MoU for the establis...</td>\n",
              "      <td>wf3362</td>\n",
              "      <td>Who founded Sanjay Sengupta?</td>\n",
              "      <td>Sanjay Sengupta founded by WhizHack Technologies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9279</th>\n",
              "      <td>{'answer_start': [52], 'text': ['bastien Rover...</td>\n",
              "      <td>Pazzi was founded by two young French inventor...</td>\n",
              "      <td>wf9279</td>\n",
              "      <td>Who founded Pazzi?</td>\n",
              "      <td>Pazzi founded by bastien Roverso</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                answers  ...                                             title\n",
              "429   {'answer_start': [28], 'text': ['Wasowski Vent...  ...                Piotr founded by Wasowski Ventures\n",
              "1162  {'answer_start': [24], 'text': ['Finless Foods']}  ...              Finless Foods founded by Mike Selden\n",
              "1808    {'answer_start': [17], 'text': ['Charlie Lee']}  ...                   Litecoin founded by Charlie Lee\n",
              "1451  {'answer_start': [52], 'text': ['cleantech Hol...  ...           Carlota Pi founded by cleantech Holaluz\n",
              "3362  {'answer_start': [295], 'text': ['WhizHack Tec...  ...  Sanjay Sengupta founded by WhizHack Technologies\n",
              "9279  {'answer_start': [52], 'text': ['bastien Rover...  ...                  Pazzi founded by bastien Roverso\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "UpDf3JhpW_kx",
        "outputId": "7d08369b-e19b-4cb8-af95-aeeed2a8b99e"
      },
      "source": [
        "# Dataset with questions for acquired_by relationship\n",
        "\n",
        "who_acquired = df[df['string_id']=='acquired_by']\n",
        "who_acquired['answers'] = who_acquired.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "who_acquired['context'] = who_acquired['sentence']\n",
        "who_acquired['id'] = 'wa' + who_acquired.index.map(str)\n",
        "who_acquired['question'] = who_acquired.apply(lambda row: 'Who acquired ' + row.entities[0] + '?', axis = 1)\n",
        "who_acquired['title'] = who_acquired.apply(lambda row: row.entities[0] + ' acquired by ' + row.entities[1], axis = 1)\n",
        "\n",
        "what_was_acquired = df[df['string_id']=='acquired_by']\n",
        "what_was_acquired['answers'] = what_was_acquired.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "what_was_acquired['context'] = what_was_acquired['sentence']\n",
        "what_was_acquired['id'] = 'wwa' + what_was_acquired.index.map(str)\n",
        "what_was_acquired['question'] = what_was_acquired.apply(lambda row: 'What was acquired by ' + row.entities[1] + '?', axis = 1)\n",
        "what_was_acquired['title'] = what_was_acquired.apply(lambda row: row.entities[0] + ' acquired by ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [who_acquired, what_was_acquired]\n",
        "acquired_by = pd.concat(frames)\n",
        "acquired_by.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "acquired_by.sample(6)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5614</th>\n",
              "      <td>{'answer_start': [39], 'text': ['TikTok']}</td>\n",
              "      <td>The real reason Microsoft wants to buy TikTok</td>\n",
              "      <td>wa5614</td>\n",
              "      <td>Who acquired Microsoft?</td>\n",
              "      <td>Microsoft acquired by TikTok</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11615</th>\n",
              "      <td>{'answer_start': [4], 'text': ['Hummingbird Ba...</td>\n",
              "      <td>The Hummingbird Bakery, a London-based America...</td>\n",
              "      <td>wwa11615</td>\n",
              "      <td>What was acquired by Acropolis Capital?</td>\n",
              "      <td>Hummingbird Bakery acquired by Acropolis Capital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5549</th>\n",
              "      <td>{'answer_start': [43], 'text': ['Spell Securit...</td>\n",
              "      <td>Qualys has acquired the software assets of Spe...</td>\n",
              "      <td>wa5549</td>\n",
              "      <td>Who acquired Qualys?</td>\n",
              "      <td>Qualys acquired by Spell Security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2565</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Kaseya']}</td>\n",
              "      <td>Kaseya acquires RocketCyber to bring SOC solut...</td>\n",
              "      <td>wwa2565</td>\n",
              "      <td>What was acquired by RocketCyber?</td>\n",
              "      <td>Kaseya acquired by RocketCyber</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10104</th>\n",
              "      <td>{'answer_start': [143], 'text': ['Hino']}</td>\n",
              "      <td>While Hyundai's sales were up, Toyota sold few...</td>\n",
              "      <td>wa10104</td>\n",
              "      <td>Who acquired Hyundai?</td>\n",
              "      <td>Hyundai acquired by Hino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5463</th>\n",
              "      <td>{'answer_start': [204], 'text': ['Shafqat Isla...</td>\n",
              "      <td>â€œOver the years, NewsCred has established itse...</td>\n",
              "      <td>wa5463</td>\n",
              "      <td>Who acquired NewsCred?</td>\n",
              "      <td>NewsCred acquired by Shafqat Islam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 answers  ...                                             title\n",
              "5614          {'answer_start': [39], 'text': ['TikTok']}  ...                      Microsoft acquired by TikTok\n",
              "11615  {'answer_start': [4], 'text': ['Hummingbird Ba...  ...  Hummingbird Bakery acquired by Acropolis Capital\n",
              "5549   {'answer_start': [43], 'text': ['Spell Securit...  ...                 Qualys acquired by Spell Security\n",
              "2565           {'answer_start': [0], 'text': ['Kaseya']}  ...                    Kaseya acquired by RocketCyber\n",
              "10104          {'answer_start': [143], 'text': ['Hino']}  ...                          Hyundai acquired by Hino\n",
              "5463   {'answer_start': [204], 'text': ['Shafqat Isla...  ...                NewsCred acquired by Shafqat Islam\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-evv14IhVres",
        "outputId": "ff407417-a899-4e67-b62f-c146cce34b5e"
      },
      "source": [
        "# Dataset with questions for invested_in relationship\n",
        "\n",
        "who_invested_in = df[df['string_id']=='invested_in']\n",
        "who_invested_in['answers'] = who_invested_in.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "who_invested_in['context'] = who_invested_in['sentence']\n",
        "who_invested_in['id'] = 'wii' + who_invested_in.index.map(str)\n",
        "who_invested_in['question'] = who_invested_in.apply(lambda row: 'Who invested in ' + row.entities[0] + '?', axis = 1)\n",
        "who_invested_in['title'] = who_invested_in.apply(lambda row: row.entities[0] + ' invested in ' + row.entities[1], axis = 1)\n",
        "\n",
        "what_was_invested_in = df[df['string_id']=='invested_in']\n",
        "what_was_invested_in['answers'] = what_was_invested_in.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "what_was_invested_in['context'] = what_was_invested_in['sentence']\n",
        "what_was_invested_in['id'] = 'wwii' + what_was_invested_in.index.map(str)\n",
        "what_was_invested_in['question'] = what_was_invested_in.apply(lambda row: 'In what did ' + row.entities[1] + ' invested?', axis = 1)\n",
        "what_was_invested_in['title'] = what_was_invested_in.apply(lambda row: row.entities[0] + ' invested in ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [who_invested_in, what_was_invested_in]\n",
        "invested_in = pd.concat(frames)\n",
        "invested_in.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "invested_in.sample(6)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>{'answer_start': [235], 'text': ['Highland Eur...</td>\n",
              "      <td>Today Modulr a digital alternative to commerci...</td>\n",
              "      <td>wii586</td>\n",
              "      <td>Who invested in Modulr?</td>\n",
              "      <td>Modulr invested in Highland Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>{'answer_start': [1], 'text': ['ActionIQ']}</td>\n",
              "      <td>\"ActionIQ, the leading customer data platform ...</td>\n",
              "      <td>wwii50</td>\n",
              "      <td>In what did March Capital Partners invested?</td>\n",
              "      <td>ActionIQ invested in March Capital Partners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3982</th>\n",
              "      <td>{'answer_start': [61], 'text': ['Blossom Capit...</td>\n",
              "      <td>According to data from Beauhurst, however, inv...</td>\n",
              "      <td>wii3982</td>\n",
              "      <td>Who invested in Beauhurst?</td>\n",
              "      <td>Beauhurst invested in Blossom Capital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6840</th>\n",
              "      <td>{'answer_start': [123], 'text': ['Green Invoic...</td>\n",
              "      <td>- Israeli private equity fund Fortissimo Capit...</td>\n",
              "      <td>wii6840</td>\n",
              "      <td>Who invested in Fortissimo Capital?</td>\n",
              "      <td>Fortissimo Capital invested in Green Invoice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2151</th>\n",
              "      <td>{'answer_start': [109], 'text': ['CynLr']}</td>\n",
              "      <td>China-based Elite Technology raised $14 millio...</td>\n",
              "      <td>wii2151</td>\n",
              "      <td>Who invested in Elite Technology?</td>\n",
              "      <td>Elite Technology invested in CynLr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2351</th>\n",
              "      <td>{'answer_start': [41], 'text': ['Founders Fund']}</td>\n",
              "      <td>Notably, he was instrumental in enabling Found...</td>\n",
              "      <td>wwii2351</td>\n",
              "      <td>In what did Postmates invested?</td>\n",
              "      <td>Founders Fund invested in Postmates</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                answers  ...                                         title\n",
              "586   {'answer_start': [235], 'text': ['Highland Eur...  ...            Modulr invested in Highland Europe\n",
              "50          {'answer_start': [1], 'text': ['ActionIQ']}  ...   ActionIQ invested in March Capital Partners\n",
              "3982  {'answer_start': [61], 'text': ['Blossom Capit...  ...         Beauhurst invested in Blossom Capital\n",
              "6840  {'answer_start': [123], 'text': ['Green Invoic...  ...  Fortissimo Capital invested in Green Invoice\n",
              "2151         {'answer_start': [109], 'text': ['CynLr']}  ...            Elite Technology invested in CynLr\n",
              "2351  {'answer_start': [41], 'text': ['Founders Fund']}  ...           Founders Fund invested in Postmates\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "ZDsajSbodC4E",
        "outputId": "be852426-b5c5-460f-be50-fcdd4dddafcd"
      },
      "source": [
        "# Dataset with questions for CEO_of relationship\n",
        "\n",
        "ceo_of_what = df[df['string_id']=='CEO_of']\n",
        "ceo_of_what['answers'] = ceo_of_what.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "ceo_of_what['context'] = ceo_of_what['sentence']\n",
        "ceo_of_what['id'] = 'cow' + ceo_of_what.index.map(str)\n",
        "ceo_of_what['question'] = ceo_of_what.apply(lambda row: 'In which company ' + row.entities[0] + ' is the CEO?', axis = 1)\n",
        "ceo_of_what['title'] = ceo_of_what.apply(lambda row: row.entities[0] + ' CEO of ' + row.entities[1], axis = 1)\n",
        "\n",
        "who_is_ceo = df[df['string_id']=='invested_in']\n",
        "who_is_ceo['answers'] = who_is_ceo.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "who_is_ceo['context'] = who_is_ceo['sentence']\n",
        "who_is_ceo['id'] = 'wic' + who_is_ceo.index.map(str)\n",
        "who_is_ceo['question'] = who_is_ceo.apply(lambda row: 'Who is the CEO of ' + row.entities[1] + '?', axis = 1)\n",
        "who_is_ceo['title'] = who_is_ceo.apply(lambda row: row.entities[0] + ' CEO of ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [ceo_of_what, who_is_ceo]\n",
        "CEO_of = pd.concat(frames)\n",
        "CEO_of.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "CEO_of.sample(6)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3434</th>\n",
              "      <td>{'answer_start': [135], 'text': ['nTopology']}</td>\n",
              "      <td>\"nTopology is excited to announce our first re...</td>\n",
              "      <td>cow3434</td>\n",
              "      <td>In which company Bradley Rothenberg is the CEO?</td>\n",
              "      <td>Bradley Rothenberg CEO of nTopology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6488</th>\n",
              "      <td>{'answer_start': [0], 'text': ['OneTrust']}</td>\n",
              "      <td>OneTrust, a provider of privacy, security and ...</td>\n",
              "      <td>wic6488</td>\n",
              "      <td>Who is the CEO of TCV?</td>\n",
              "      <td>OneTrust CEO of TCV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4002</th>\n",
              "      <td>{'answer_start': [18], 'text': ['Jim']}</td>\n",
              "      <td>In 2018 and 2019, Jim invested in and led Rece...</td>\n",
              "      <td>wic4002</td>\n",
              "      <td>Who is the CEO of Receptra Naturals?</td>\n",
              "      <td>Jim CEO of Receptra Naturals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9845</th>\n",
              "      <td>{'answer_start': [28], 'text': ['Company']}</td>\n",
              "      <td>applicationsBy end of 2020, Company expects to...</td>\n",
              "      <td>wic9845</td>\n",
              "      <td>Who is the CEO of Ingredion Incorporated?</td>\n",
              "      <td>Company CEO of Ingredion Incorporated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8665</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Memphis Meats']}</td>\n",
              "      <td>Memphis Meats has raised over $20 million in f...</td>\n",
              "      <td>wic8665</td>\n",
              "      <td>Who is the CEO of Crunchbase?</td>\n",
              "      <td>Memphis Meats CEO of Crunchbase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7596</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Foundation Cap...</td>\n",
              "      <td>Foundation Capital led its $4.3 million seed r...</td>\n",
              "      <td>wic7596</td>\n",
              "      <td>Who is the CEO of Y Combinator?</td>\n",
              "      <td>Foundation Capital CEO of Y Combinator</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                answers  ...                                   title\n",
              "3434     {'answer_start': [135], 'text': ['nTopology']}  ...     Bradley Rothenberg CEO of nTopology\n",
              "6488        {'answer_start': [0], 'text': ['OneTrust']}  ...                     OneTrust CEO of TCV\n",
              "4002            {'answer_start': [18], 'text': ['Jim']}  ...            Jim CEO of Receptra Naturals\n",
              "9845        {'answer_start': [28], 'text': ['Company']}  ...   Company CEO of Ingredion Incorporated\n",
              "8665   {'answer_start': [0], 'text': ['Memphis Meats']}  ...         Memphis Meats CEO of Crunchbase\n",
              "7596  {'answer_start': [0], 'text': ['Foundation Cap...  ...  Foundation Capital CEO of Y Combinator\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "_rxbzjOIls6r",
        "outputId": "bbecebf2-d9cc-4386-ecd0-8b29aa068d05"
      },
      "source": [
        "# Dataset with questions for subsidiary_of relationship\n",
        "\n",
        "subsidiary_of_what = df[df['string_id']=='subsidiary_of']\n",
        "subsidiary_of_what['answers'] = subsidiary_of_what.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "subsidiary_of_what['context'] = subsidiary_of_what['sentence']\n",
        "subsidiary_of_what['id'] = 'sow' + subsidiary_of_what.index.map(str)\n",
        "subsidiary_of_what['question'] = subsidiary_of_what.apply(lambda row: row.entities[0] + ' is a subsidiary of which company?', axis = 1)\n",
        "subsidiary_of_what['title'] = subsidiary_of_what.apply(lambda row: row.entities[0] + ' subsidiary of ' + row.entities[1], axis = 1)\n",
        "\n",
        "parent_company_of = df[df['string_id']=='subsidiary_of']\n",
        "parent_company_of['answers'] = parent_company_of.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "parent_company_of['context'] = parent_company_of['sentence']\n",
        "parent_company_of['id'] = 'pco' + parent_company_of.index.map(str)\n",
        "parent_company_of['question'] = parent_company_of.apply(lambda row: 'Of which comapny is ' + row.entities[1] + ' a parent company?', axis = 1)\n",
        "parent_company_of['title'] = parent_company_of.apply(lambda row: row.entities[0] + ' subsidiary of ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [subsidiary_of_what, parent_company_of]\n",
        "subsidiary_of = pd.concat(frames)\n",
        "subsidiary_of.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "subsidiary_of.sample(6)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12002</th>\n",
              "      <td>{'answer_start': [53], 'text': ['Tel Aviv-base...</td>\n",
              "      <td>Itâ€™s worth noting that Metro Skyway, a subsidi...</td>\n",
              "      <td>sow12002</td>\n",
              "      <td>Metro Skyway is a subsidiary of which company?</td>\n",
              "      <td>Metro Skyway subsidiary of Tel Aviv-based Urba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5339</th>\n",
              "      <td>{'answer_start': [230], 'text': ['Microsoft']}</td>\n",
              "      <td>I mean, we've sort of joked for years about Mi...</td>\n",
              "      <td>sow5339</td>\n",
              "      <td>AAPL is a subsidiary of which company?</td>\n",
              "      <td>AAPL subsidiary of Microsoft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1034</th>\n",
              "      <td>{'answer_start': [151], 'text': ['BP']}</td>\n",
              "      <td>When it comes to bringing electricity to UK fa...</td>\n",
              "      <td>sow1034</td>\n",
              "      <td>Zennor is a subsidiary of which company?</td>\n",
              "      <td>Zennor subsidiary of BP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9007</th>\n",
              "      <td>{'answer_start': [76], 'text': ['Mosa Meat']}</td>\n",
              "      <td>It was announced this morning that Netherlands...</td>\n",
              "      <td>pco9007</td>\n",
              "      <td>Of which comapny is Blue Horizon Ventures a pa...</td>\n",
              "      <td>Mosa Meat subsidiary of Blue Horizon Ventures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10122</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Capital One']}</td>\n",
              "      <td>Capital One deserves credit for expanding its ...</td>\n",
              "      <td>pco10122</td>\n",
              "      <td>Of which comapny is Spark Miles for Business a...</td>\n",
              "      <td>Capital One subsidiary of Spark Miles for Busi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1789</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Kosala Hemacha...</td>\n",
              "      <td>Kosala Hemachandra of MyEtherWallet explained ...</td>\n",
              "      <td>pco1789</td>\n",
              "      <td>Of which comapny is UX a parent company?</td>\n",
              "      <td>Kosala Hemachandra subsidiary of UX</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 answers  ...                                              title\n",
              "12002  {'answer_start': [53], 'text': ['Tel Aviv-base...  ...  Metro Skyway subsidiary of Tel Aviv-based Urba...\n",
              "5339      {'answer_start': [230], 'text': ['Microsoft']}  ...                       AAPL subsidiary of Microsoft\n",
              "1034             {'answer_start': [151], 'text': ['BP']}  ...                            Zennor subsidiary of BP\n",
              "9007       {'answer_start': [76], 'text': ['Mosa Meat']}  ...      Mosa Meat subsidiary of Blue Horizon Ventures\n",
              "10122     {'answer_start': [0], 'text': ['Capital One']}  ...  Capital One subsidiary of Spark Miles for Busi...\n",
              "1789   {'answer_start': [0], 'text': ['Kosala Hemacha...  ...                Kosala Hemachandra subsidiary of UX\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "3PkOwPjGrc49",
        "outputId": "65c0007e-9e13-4bd4-d3ca-2553f9ac0a7e"
      },
      "source": [
        "# Dataset with questions for partners_with relationship\n",
        "\n",
        "partners_with_1 = df[df['string_id']=='partners_with']\n",
        "partners_with_1['answers'] = partners_with_1.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "partners_with_1['context'] = partners_with_1['sentence']\n",
        "partners_with_1['id'] = 'pwo' + partners_with_1.index.map(str)\n",
        "partners_with_1['question'] = partners_with_1.apply(lambda row: 'Which company is a partner of ' + row.entities[0] + '?', axis = 1)\n",
        "partners_with_1['title'] = partners_with_1.apply(lambda row: row.entities[0] + ' partners with ' + row.entities[1], axis = 1)\n",
        "\n",
        "partners_with_2 = df[df['string_id']=='partners_with']\n",
        "partners_with_2['answers'] = partners_with_2.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "partners_with_2['context'] = partners_with_2['sentence']\n",
        "partners_with_2['id'] = 'pw2' + partners_with_2.index.map(str)\n",
        "partners_with_2['question'] = partners_with_2.apply(lambda row: 'Which company is a partner of ' + row.entities[1] + '?', axis = 1)\n",
        "partners_with_2['title'] = partners_with_2.apply(lambda row: row.entities[0] + ' partners with ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [partners_with_1, partners_with_2]\n",
        "partners_with = pd.concat(frames)\n",
        "partners_with.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "partners_with.sample(6)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8242</th>\n",
              "      <td>{'answer_start': [45], 'text': ['Stripe']}</td>\n",
              "      <td>The CRM business unveiled a partnership with S...</td>\n",
              "      <td>pwo8242</td>\n",
              "      <td>Which company is a partner of CRM?</td>\n",
              "      <td>CRM partners with Stripe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8177</th>\n",
              "      <td>{'answer_start': [100], 'text': ['Ooredoo Kuwa...</td>\n",
              "      <td>Meanwhile, mobility solutions firm Comviva has...</td>\n",
              "      <td>pwo8177</td>\n",
              "      <td>Which company is a partner of Comviva?</td>\n",
              "      <td>Comviva partners with Ooredoo Kuwait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6333</th>\n",
              "      <td>{'answer_start': [98], 'text': ['Uniqorn']}</td>\n",
              "      <td>While work on its SDK has still remained of pr...</td>\n",
              "      <td>pwo6333</td>\n",
              "      <td>Which company is a partner of XRApplied?</td>\n",
              "      <td>XRApplied partners with Uniqorn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9419</th>\n",
              "      <td>{'answer_start': [56], 'text': ['PayPal']}</td>\n",
              "      <td>The Data Security Council of India, in partner...</td>\n",
              "      <td>pwo9419</td>\n",
              "      <td>Which company is a partner of Data Security Co...</td>\n",
              "      <td>Data Security Council of India partners with P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>{'answer_start': [67], 'text': ['IBM']}</td>\n",
              "      <td>Samsung Electronics today announced a new plan...</td>\n",
              "      <td>pwo2473</td>\n",
              "      <td>Which company is a partner of Samsung Electron...</td>\n",
              "      <td>Samsung Electronics partners with IBM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5438</th>\n",
              "      <td>{'answer_start': [64], 'text': ['Iot Evolution']}</td>\n",
              "      <td>Huawei and Trustonic Expand Partnership with P...</td>\n",
              "      <td>pwo5438</td>\n",
              "      <td>Which company is a partner of Huawei?</td>\n",
              "      <td>Huawei partners with Iot Evolution</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                answers  ...                                              title\n",
              "8242         {'answer_start': [45], 'text': ['Stripe']}  ...                           CRM partners with Stripe\n",
              "8177  {'answer_start': [100], 'text': ['Ooredoo Kuwa...  ...               Comviva partners with Ooredoo Kuwait\n",
              "6333        {'answer_start': [98], 'text': ['Uniqorn']}  ...                    XRApplied partners with Uniqorn\n",
              "9419         {'answer_start': [56], 'text': ['PayPal']}  ...  Data Security Council of India partners with P...\n",
              "2473            {'answer_start': [67], 'text': ['IBM']}  ...              Samsung Electronics partners with IBM\n",
              "5438  {'answer_start': [64], 'text': ['Iot Evolution']}  ...                 Huawei partners with Iot Evolution\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-yUjU7B9rvbh",
        "outputId": "51110437-1776-4762-cdc2-4347938b8ec8"
      },
      "source": [
        "# Dataset with questions for owned_by relationship\n",
        "\n",
        "who_owns = df[df['string_id']=='owned_by']\n",
        "who_owns['answers'] = who_owns.apply(lambda row: {'answer_start': [row.entity_spans[1][0]],\n",
        "                                                      'text': [row.entities[1]]}, axis = 1)\n",
        "who_owns['context'] = who_owns['sentence']\n",
        "who_owns['id'] = 'wo' + who_owns.index.map(str)\n",
        "who_owns['question'] = who_owns.apply(lambda row: 'Who owns ' + row.entities[0] + '?', axis = 1)\n",
        "who_owns['title'] = who_owns.apply(lambda row: row.entities[0] + ' owned by ' + row.entities[1], axis = 1)\n",
        "\n",
        "ownes_what = df[df['string_id']=='owned_by']\n",
        "ownes_what['answers'] = ownes_what.apply(lambda row: {'answer_start': [row.entity_spans[0][0]],\n",
        "                                                      'text': [row.entities[0]]}, axis = 1)\n",
        "ownes_what['context'] = ownes_what['sentence']\n",
        "ownes_what['id'] = 'ow' + ownes_what.index.map(str)\n",
        "ownes_what['question'] = ownes_what.apply(lambda row: 'Which company does ' + row.entities[1] + ' own?', axis = 1)\n",
        "ownes_what['title'] = ownes_what.apply(lambda row: row.entities[0] + ' owned by ' + row.entities[1], axis = 1)\n",
        "\n",
        "frames = [who_owns, ownes_what]\n",
        "owned_by = pd.concat(frames)\n",
        "owned_by.drop(['end_idx','entities','entity_spans','match','original_article','sentence','start_idx','string_id'],axis=1,inplace=True)\n",
        "owned_by.sample(6)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>answers</th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>question</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7340</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Thomson-Reuter...</td>\n",
              "      <td>Thomson-Reuters is owned by the powerful Canad...</td>\n",
              "      <td>ow7340</td>\n",
              "      <td>Which company does Canadian Thomson own?</td>\n",
              "      <td>Thomson-Reuters owned by Canadian Thomson</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6729</th>\n",
              "      <td>{'answer_start': [57], 'text': ['Nielsen']}</td>\n",
              "      <td>SuperData Research, another market analyst fir...</td>\n",
              "      <td>wo6729</td>\n",
              "      <td>Who owns SuperData Research?</td>\n",
              "      <td>SuperData Research owned by Nielsen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5649</th>\n",
              "      <td>{'answer_start': [69], 'text': ['TikTok']}</td>\n",
              "      <td>Recall that Trump's executive order has prohib...</td>\n",
              "      <td>ow5649</td>\n",
              "      <td>Which company does ByteDance own?</td>\n",
              "      <td>TikTok owned by ByteDance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3008</th>\n",
              "      <td>{'answer_start': [130], 'text': ['Bakkt']}</td>\n",
              "      <td>Venuto likes Intercontinental Exchange (ICE), ...</td>\n",
              "      <td>wo3008</td>\n",
              "      <td>Who owns New York Stock Exchange?</td>\n",
              "      <td>New York Stock Exchange owned by Bakkt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9689</th>\n",
              "      <td>{'answer_start': [0], 'text': ['Uber Ele']}</td>\n",
              "      <td>Uber Ele me owned by China s Alibaba and priva...</td>\n",
              "      <td>ow9689</td>\n",
              "      <td>Which company does Alibaba own?</td>\n",
              "      <td>Uber Ele owned by Alibaba</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5422</th>\n",
              "      <td>{'answer_start': [161], 'text': ['Google']}</td>\n",
              "      <td>Google allows competitors to bid on trademarke...</td>\n",
              "      <td>wo5422</td>\n",
              "      <td>Who owns Google?</td>\n",
              "      <td>Google owned by Google</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                answers  ...                                      title\n",
              "7340  {'answer_start': [0], 'text': ['Thomson-Reuter...  ...  Thomson-Reuters owned by Canadian Thomson\n",
              "6729        {'answer_start': [57], 'text': ['Nielsen']}  ...        SuperData Research owned by Nielsen\n",
              "5649         {'answer_start': [69], 'text': ['TikTok']}  ...                  TikTok owned by ByteDance\n",
              "3008         {'answer_start': [130], 'text': ['Bakkt']}  ...     New York Stock Exchange owned by Bakkt\n",
              "9689        {'answer_start': [0], 'text': ['Uber Ele']}  ...                  Uber Ele owned by Alibaba\n",
              "5422        {'answer_start': [161], 'text': ['Google']}  ...                     Google owned by Google\n",
              "\n",
              "[6 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_9UaHFnrSGp"
      },
      "source": [
        "# Combine all and split to train and test\n",
        "\n",
        "!pip install -q datasets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "\n",
        "frames = [founded_by, acquired_by, invested_in, CEO_of, subsidiary_of, partners_with, owned_by]\n",
        "full_df = pd.concat(frames)\n",
        "df_train, df_test = train_test_split(full_df, test_size=0.2)\n",
        "train_dataset = Dataset.from_pandas(df_train)\n",
        "test_dataset = Dataset.from_pandas(df_test)\n",
        "train_dataset = train_dataset.remove_columns('__index_level_0__')\n",
        "test_dataset = test_dataset.remove_columns('__index_level_0__')"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ya3relQos-0h"
      },
      "source": [
        "# Preprocessing the training data\n",
        "\n",
        "def prepare_train_features(examples):\n",
        "    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n",
        "    # in one example possible giving several features when a context is long, each of those features having a\n",
        "    # context that overlaps a bit the context of the previous feature.\n",
        "    tokenized_examples = tokenizer(\n",
        "        examples[\"question\"],\n",
        "        examples[\"context\"],\n",
        "        truncation=\"only_second\",\n",
        "        max_length=max_length,\n",
        "        stride=doc_stride,\n",
        "        return_overflowing_tokens=True,\n",
        "        return_offsets_mapping=True,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "\n",
        "    # Since one example might give us several features if it has a long context, we need a map from a feature to\n",
        "    # its corresponding example. This key gives us just that.\n",
        "    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n",
        "    # The offset mappings will give us a map from token to character position in the original context. This will\n",
        "    # help us compute the start_positions and end_positions.\n",
        "    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n",
        "\n",
        "    # Let's label those examples!\n",
        "    tokenized_examples[\"start_positions\"] = []\n",
        "    tokenized_examples[\"end_positions\"] = []\n",
        "\n",
        "    for i, offsets in enumerate(offset_mapping):\n",
        "        # We will label impossible answers with the index of the CLS token.\n",
        "        input_ids = tokenized_examples[\"input_ids\"][i]\n",
        "        cls_index = input_ids.index(tokenizer.cls_token_id)\n",
        "\n",
        "        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n",
        "        sequence_ids = tokenized_examples.sequence_ids(i)\n",
        "\n",
        "        # One example can give several spans, this is the index of the example containing this span of text.\n",
        "        sample_index = sample_mapping[i]\n",
        "        answers = examples[\"answers\"][sample_index]\n",
        "        # If no answers are given, set the cls_index as answer.\n",
        "        if len(answers[\"answer_start\"]) == 0:\n",
        "            tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "            tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "        else:\n",
        "            # Start/end character index of the answer in the text.\n",
        "            start_char = answers[\"answer_start\"][0]\n",
        "            end_char = start_char + len(answers[\"text\"][0])\n",
        "\n",
        "            # Start token index of the current span in the text.\n",
        "            token_start_index = 0\n",
        "            while sequence_ids[token_start_index] != 1:\n",
        "                token_start_index += 1\n",
        "\n",
        "            # End token index of the current span in the text.\n",
        "            token_end_index = len(input_ids) - 1\n",
        "            while sequence_ids[token_end_index] != 1:\n",
        "                token_end_index -= 1\n",
        "\n",
        "            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n",
        "            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n",
        "                tokenized_examples[\"start_positions\"].append(cls_index)\n",
        "                tokenized_examples[\"end_positions\"].append(cls_index)\n",
        "            else:\n",
        "                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n",
        "                # Note: we could go after the last offset if the answer is the last word (edge case).\n",
        "                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n",
        "                    token_start_index += 1\n",
        "                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n",
        "                while offsets[token_end_index][1] >= end_char:\n",
        "                    token_end_index -= 1\n",
        "                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n",
        "\n",
        "    return tokenized_examples"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639,
          "referenced_widgets": [
            "be73d2f4c8204fe8b29606419b0c9207",
            "e3305090792a480193b47f3f0c57edb5",
            "2bdde1a7dced41af861374dc6cd73b51",
            "cf49baaee78747c7b233533c4913f849",
            "462ff2b30a3a4d59a6a7cd67078afe61",
            "4cb07c5506e4402fb45a97bd41019232",
            "a5b674881e114d94ba7b11859c4feedc",
            "9ab85d09ee4c444ab0298172eab3523a",
            "3c7c104d0a7c49be915505a59402edaf",
            "9adb5f40b8dd43d3b3484796e99aaa65",
            "f5110458a36d4f5a9344114022180c62",
            "f2784386c37444bdb89592b9d44a5327",
            "b39bcf25402f452f9a6f77624067e7bf",
            "c3921a74257b47f389df4fdcdf04ce78",
            "f532e20dd8c94d49bc8b66ded47de181",
            "67614bce80b3434ebafe568a19c281ae"
          ]
        },
        "id": "37HmTStR0wrm",
        "outputId": "31672e15-b623-4825-ce05-3d1bbb98e49b"
      },
      "source": [
        "# Perform tokenizing\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "max_length = 512 # The maximum allowed length of a feature (question and context)\n",
        "doc_stride = 128 # The authorized overlap between two part of the context when splitting it is needed.\n",
        "tokenized_train = train_dataset.map(prepare_train_features, batched=True, remove_columns=train_dataset.column_names)\n",
        "tokenized_val = test_dataset.map(prepare_train_features, batched=True, remove_columns=test_dataset.column_names)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/0e1bbfda7f63a99bb52e3915dcf10c3c92122b827d92eb2d34ce94ee79ba486c.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/75abb59d7a06f4f640158a9bfcde005264e59e8d566781ab1415b139d2e4c603.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/distilbert-base-uncased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/8c8624b8ac8aa99c60c912161f8332de003484428c47906d7ff7eb7f73eecdbb.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "be73d2f4c8204fe8b29606419b0c9207",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3c7c104d0a7c49be915505a59402edaf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPq7wkbAI5Rj",
        "outputId": "369adfe6-7c2a-440b-bd94-623073dc0620"
      },
      "source": [
        "# We will finetune a pretrained model\n",
        "\n",
        "from transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, default_data_collator\n",
        "import torch\n",
        "\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading configuration file https://huggingface.co/distilbert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/23454919702d26495337f3da04d1655c7ee010d5ec9d77bdb9e399e00302c0a1.d423bdf2f58dc8b77d5f5d18028d7ae4a72dcfd8f468e81fe979ada957a8c361\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.8.2\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForQuestionAnswering: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dM0PaJzRb1iz",
        "outputId": "0e26d823-3cea-4024-9057-5b4d493a37d2"
      },
      "source": [
        "# Additional training with our data (3 epochs)\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"test-questions\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        ")\n",
        "\n",
        "data_collator = default_data_collator\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_train,\n",
        "    eval_dataset=tokenized_val,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "***** Running training *****\n",
            "  Num examples = 19876\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3729\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3729' max='3729' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3729/3729 59:06, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.546400</td>\n",
              "      <td>0.375702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.295100</td>\n",
              "      <td>0.321313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.179300</td>\n",
              "      <td>0.356019</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model checkpoint to test-questions/checkpoint-500\n",
            "Configuration saved in test-questions/checkpoint-500/config.json\n",
            "Model weights saved in test-questions/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to test-questions/checkpoint-1000\n",
            "Configuration saved in test-questions/checkpoint-1000/config.json\n",
            "Model weights saved in test-questions/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4970\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to test-questions/checkpoint-1500\n",
            "Configuration saved in test-questions/checkpoint-1500/config.json\n",
            "Model weights saved in test-questions/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to test-questions/checkpoint-2000\n",
            "Configuration saved in test-questions/checkpoint-2000/config.json\n",
            "Model weights saved in test-questions/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4970\n",
            "  Batch size = 16\n",
            "Saving model checkpoint to test-questions/checkpoint-2500\n",
            "Configuration saved in test-questions/checkpoint-2500/config.json\n",
            "Model weights saved in test-questions/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to test-questions/checkpoint-3000\n",
            "Configuration saved in test-questions/checkpoint-3000/config.json\n",
            "Model weights saved in test-questions/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-3000/special_tokens_map.json\n",
            "Saving model checkpoint to test-questions/checkpoint-3500\n",
            "Configuration saved in test-questions/checkpoint-3500/config.json\n",
            "Model weights saved in test-questions/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in test-questions/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in test-questions/checkpoint-3500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 4970\n",
            "  Batch size = 16\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3729, training_loss=0.4066481606894442, metrics={'train_runtime': 3547.0158, 'train_samples_per_second': 16.811, 'train_steps_per_second': 1.051, 'total_flos': 1.2156449330700288e+16, 'train_loss': 0.4066481606894442, 'epoch': 3.0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "MU5zFLh45eir",
        "outputId": "19f924df-3f36-402e-b08e-5ccbe9b0326e"
      },
      "source": [
        "raw_predictions = trainer.predict(tokenized_val)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 4970\n",
            "  Batch size = 16\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='311' max='311' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [311/311 01:26]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3K_TQqFU2qZP"
      },
      "source": [
        "# Get the best predictions for the val dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "n_best_size = 1 # want the top prediction\n",
        "max_answer_length = 40\n",
        "answers = []\n",
        "\n",
        "for i in range (len(df_test)):\n",
        "  start_logits = raw_predictions.predictions[0][i]\n",
        "  end_logits = raw_predictions.predictions[1][i]\n",
        "  offset_mapping = validation_features[i][\"offset_mapping\"]\n",
        "  # The first feature comes from the first example. For the more general case, we will need to be match the example_id to\n",
        "  # an example index\n",
        "  context = test_dataset[i][\"context\"]\n",
        "\n",
        "  # Gather the indices the best start/end logits:\n",
        "  start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "  end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n",
        "  valid_answers = []\n",
        "  for start_index in start_indexes:\n",
        "      for end_index in end_indexes:\n",
        "          # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n",
        "          # to part of the input_ids that are not in the context.\n",
        "          if (\n",
        "              start_index >= len(offset_mapping)\n",
        "              or end_index >= len(offset_mapping)\n",
        "              or offset_mapping[start_index] is None\n",
        "              or offset_mapping[end_index] is None\n",
        "          ):\n",
        "              continue\n",
        "          # Don't consider answers with a length that is either < 0 or > max_answer_length.\n",
        "          if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n",
        "              continue\n",
        "          if start_index <= end_index: # We need to refine that test to check the answer is inside the context\n",
        "              start_char = offset_mapping[start_index][0]\n",
        "              end_char = offset_mapping[end_index][1]\n",
        "              valid_answers.append(\n",
        "                  {\n",
        "                      \"score\": start_logits[start_index] + end_logits[end_index],\n",
        "                      \"text\": context[start_char: end_char]\n",
        "                  }\n",
        "              )\n",
        "\n",
        "  valid_answers = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[:n_best_size]\n",
        "  answers.append(valid_answers)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJmhqL5V9Pig",
        "outputId": "204db61d-d2ad-44d6-b31a-2818ed7dcf01"
      },
      "source": [
        "# Looking at some random questions and predictions\n",
        "\n",
        "import random\n",
        "\n",
        "random_rows = random.sample(range(len(df_test)), 10)\n",
        "\n",
        "for i in random_rows:\n",
        "  print(\"\\nQuestion:\")\n",
        "  print(df_test.iloc[i]['question'])\n",
        "  print(\"Answer:\")\n",
        "  print(df_test.iloc[i]['answers']['text'][0])\n",
        "  print(\"Predicted:\")\n",
        "  print(answers[i])\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Question:\n",
            "Which company is a partner of DisruptAD?\n",
            "Answer:\n",
            "MENA\n",
            "Predicted:\n",
            "[{'score': 11.063078, 'text': 'MENA'}]\n",
            "\n",
            "Question:\n",
            "Which company does Jaak own?\n",
            "Answer:\n",
            "Dot Blockchain Media\n",
            "Predicted:\n",
            "[{'score': 16.93885, 'text': 'um that can b'}]\n",
            "\n",
            "Question:\n",
            "In which company Evan Gappelberg is the CEO?\n",
            "Answer:\n",
            "Nextech AR\n",
            "Predicted:\n",
            "[{'score': 15.248435, 'text': 'hange u'}]\n",
            "\n",
            "Question:\n",
            "In what did Third Swedish National Pension Fund invested?\n",
            "Answer:\n",
            "Readly\n",
            "Predicted:\n",
            "[{'score': 13.873442, 'text': 'In June '}]\n",
            "\n",
            "Question:\n",
            "Who acquired Uber?\n",
            "Answer:\n",
            "Postmates\n",
            "Predicted:\n",
            "[{'score': 14.369099, 'text': 'Meanwhile, according to Axios'}]\n",
            "\n",
            "Question:\n",
            "Who invested in CaptivateIQ?\n",
            "Answer:\n",
            "Accel\n",
            "Predicted:\n",
            "[{'score': 17.347366, 'text': 'Accel'}]\n",
            "\n",
            "Question:\n",
            "Who is the CEO of Husqvarna Group?\n",
            "Answer:\n",
            "Soil Scout\n",
            "Predicted:\n",
            "[{'score': 17.897842, 'text': 'T se'}]\n",
            "\n",
            "Question:\n",
            "In what did TikTok invested?\n",
            "Answer:\n",
            "Tencent\n",
            "Predicted:\n",
            "[{'score': 13.327038, 'text': 'ByteDance, briefly'}]\n",
            "\n",
            "Question:\n",
            "Who is the CEO of Crosslink Capital?\n",
            "Answer:\n",
            "Feedback Loop\n",
            "Predicted:\n",
            "[{'score': 18.612188, 'text': 'Feedback Loop'}]\n",
            "\n",
            "Question:\n",
            "What was acquired by Axoni?\n",
            "Answer:\n",
            "Axoni\n",
            "Predicted:\n",
            "[{'score': 16.99214, 'text': ' Axoni also announ'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjYkQY4-Egb5"
      },
      "source": [
        "Not perfect, but we do get some correct answers"
      ]
    }
  ]
}
