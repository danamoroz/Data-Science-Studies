{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "Copy of Assignment3Solutions_submit.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow7Ex1ITLshb"
      },
      "source": [
        "Dana Rozenblum & Nitzan Tal\n",
        "# Assignment 3 Solutions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwfBEDDeLshg"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.stats"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lodqci7Lshu"
      },
      "source": [
        "## Model quality"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koiOBZOfLshv",
        "outputId": "f8041edc-394b-472e-e246-43e1df99f61d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "newPositive = 1235\n",
        "n = 1600\n",
        "newProb = newPositive / n\n",
        "h0Prob = 0.75\n",
        "h0Var = h0Prob * (1 - h0Prob)\n",
        "means = []\n",
        "bootSize = 10000\n",
        "\n",
        "z = (newProb - h0Prob) / np.sqrt(h0Var / n)\n",
        "pValue = 1 - scipy.stats.norm(0, 1).cdf(z)\n",
        "pValueP = round(pValue * 100,1)\n",
        "print (\"Analytical p-value: \" + str(pValueP) + \"%\")\n",
        "\n",
        "# Bootstrapped p value: simulation-like approach, sampling from H0\n",
        "sample1 =  np.random.binomial(n,h0Prob,bootSize) / n\n",
        "pval= 1-np.mean(newProb > sample1)\n",
        "pval = round(pval * 100,1)\n",
        "\n",
        "print (\"Bootstrapped p-value: \" + str(pval) + \"%\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Analytical p-value: 2.2%\n",
            "Bootstrapped p-value: 2.2%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2DA1p974v0O"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "Analytical p-value: 2.2%\n",
        "\n",
        "Bootstrapped p-value: 2.2%"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Na2Hz2zLsh5"
      },
      "source": [
        "## Comparing salaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1jo27QMLsh6",
        "outputId": "d5d38db4-c057-4251-98dc-a4edd45dbc1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data1 = np.genfromtxt('salaries1.txt')\n",
        "data2 = np.genfromtxt('salaries2.txt')\n",
        "sig = 0.05\n",
        "\n",
        "mean1 = np.mean(data1)\n",
        "mean2 = np.mean(data2)\n",
        "n1 = data1.size\n",
        "n2 = data2.size\n",
        " \n",
        "s1_2 = scipy.stats.tvar(data1)/n1\n",
        " \n",
        "s2_2 = scipy.stats.tvar(data2)/n2\n",
        "denominator = np.sqrt(s1_2 + s2_2)\n",
        "t = (mean1 - mean2) / denominator\n",
        "df_t = n1 + n2 - 2\n",
        "\n",
        "p_value = 2 * scipy.stats.t(df = df_t).cdf(t)\n",
        "\n",
        "pValuePrint = round(p_value * 100,1)\n",
        "sigPrint = round(sig * 100,0)\n",
        "print(\"Two-sided p-value is \" + str(pValuePrint) + \"%\")\n",
        "print(\"At \" + str(sigPrint) + \"% significance:\")\n",
        "if (p_value < sig):\n",
        "    print (\"The null hypothesis that the salary for both occupations is the same is rejected\")\n",
        "else:\n",
        "    print (\"The null hypothesis that the salary for both occupations is the same cannot be rejected\")\n",
        "    \n",
        "#Sanity check\n",
        "print(\"Sanity check: calculate with scipy.stats.ttest_ind:\")\n",
        "print(scipy.stats.ttest_ind(data1,data2,equal_var = False))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Two-sided p-value is 3.5%\n",
            "At 5.0% significance:\n",
            "The null hypothesis that the salary for both occupations is the same is rejected\n",
            "Sanity check: calculate with scipy.stats.ttest_ind:\n",
            "Ttest_indResult(statistic=-2.129970166236807, pvalue=0.034916573358014256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FePHbFjR8PCu"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "Two-sided p-value is 3.5%\n",
        "\n",
        "At 5.0% significance:\n",
        "The null hypothesis that the salary for both occupations is the same is rejected.\n",
        "\n",
        "Sanity check: calculate with scipy.stats.ttest_ind:\n",
        "\n",
        "Ttest_indResult(statistic=-2.129970166236807, pvalue=0.034916573358014256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO86kqjVLsiB"
      },
      "source": [
        "## Counting bombs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huUbBMmaLsiD"
      },
      "source": [
        "### 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyk75xZNLsiE",
        "outputId": "da8bc335-36b8-45f4-fadf-f00e25b1e2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "k = np.array([0,1,2,3,4,5], dtype = \"int\")\n",
        "nk = np.array([229,211,93,35,7,1])\n",
        "n_total = np.sum(nk)\n",
        "\n",
        "lam = 537 / n_total # was given to us\n",
        "print(\"Estimation of the parameter ðœ† for Poisson distribution from our data: \" + str(round(lam,7)))\n",
        "\n",
        "distP = scipy.stats.poisson(lam)\n",
        "expect = distP.pmf(np.arange(6))* 576\n",
        "\n",
        "print (\"Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5 (last cell is exactly 5):\")\n",
        "print(np.around(expect))\n",
        "\n",
        "expect[5]=(1-distP.cdf(4))*576     \n",
        "\n",
        "print (\"Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5+ (last cell is 5+):\")\n",
        "print(np.around(expect))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimation of the parameter ðœ† for Poisson distribution from our data: 0.9322917\n",
            "Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5 (last cell is exactly 5):\n",
            "[227. 211.  99.  31.   7.   1.]\n",
            "Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5+ (last cell is 5+):\n",
            "[227. 211.  99.  31.   7.   2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZt3g2aUFCkx"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "Estimation of the parameter ðœ† for Poisson distribution from our data: 0.9322917\n",
        "\n",
        "Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5 (last cell is exactly 5):\n",
        "\n",
        "[227.  211.   99.   31.    7.    1.]\n",
        "\n",
        "Expected number of regions ð‘›Ìƒð‘˜ with number of bombs from 0 to 5+ (last cell is 5+):\n",
        "\n",
        "[227.  211.   99.   31.    7.    2.]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQCe6NFhLsiR"
      },
      "source": [
        "### 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qzBCzGNLsiS",
        "outputId": "4a06bd55-2fb0-401a-a04d-e90584f3b496",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t_sum_calc = np.power(nk - expect, 2) / expect\n",
        "bombs_t = np.sum(t_sum_calc)\n",
        "\n",
        "print(\"Sample value of T: \" + str(bombs_t))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample value of T: 1.169154675181436\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51BZipdyHezD"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "Sample value of T: 1.169154675181436"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Drmms2i9Lsi4"
      },
      "source": [
        "### 3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "usrGQ5nFLsi8",
        "outputId": "18fdd561-444f-47ab-8add-3b0bf6878c6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t_p_value = 1 - scipy.stats.chi2.cdf(bombs_t, 4)\n",
        "\n",
        "print(\"P-value: \" + str(round(t_p_value,6)))\n",
        "if (t_p_value < 0.05):\n",
        "    print(\"Is low enough to reject the hypothesis about the Poisson distribution\")\n",
        "else:\n",
        "    print(\"Is not low enough to reject the hypothesis about the Poisson distribution\")\n",
        "# sanity check\n",
        "print(\"Sanity check: calculate with scipy.stats.chisquare:\")\n",
        "scipy.stats.chisquare([229,211,93,35,7,1],expect,1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "P-value: 0.883151\n",
            "Is not low enough to reject the hypothesis about the Poisson distribution\n",
            "Sanity check: calculate with scipy.stats.chisquare:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Power_divergenceResult(statistic=1.169154675181436, pvalue=0.8831505189191594)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-KZ1VkMyIRA5"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "P-value: 0.883151\n",
        "\n",
        "Is not low enough to reject the hypothesis about the Poisson distribution.\n",
        "\n",
        "Sanity check: calculate with scipy.stats.chisquare:\n",
        "\n",
        "Power_divergenceResult(statistic=1.169154675181436, pvalue=0.8831505189191594)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptwtezRSLsjF"
      },
      "source": [
        "### Russian cities, continued"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgxJcBwLLsjG",
        "outputId": "2ccbc893-bafd-44d3-8345-0b3a1bd6b6a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "cities = np.genfromtxt('russian_cities_g_9k.csv')\n",
        "cities_sig_level = 0.05\n",
        "\n",
        "cities_a = np.min(cities)\n",
        "cities_n = cities.size\n",
        "cities_ln = np.log(cities)\n",
        "cities_b = cities_n / (np.sum(cities_ln) - cities_n * np.log(cities_a))\n",
        "\n",
        "dist = scipy.stats.pareto(cities_b, scale = cities_a)\n",
        "ks_stat, ks_pvalue = scipy.stats.kstest(cities, dist.cdf)\n",
        "\n",
        "print(\"KS P-value: \" + str(ks_pvalue))\n",
        "\n",
        "if (ks_pvalue < cities_sig_level):\n",
        "    print(\"According to Kolmogorov-Smirnov method the data was not generated by the Pareto distributions\")\n",
        "else:\n",
        "    print(\"According to Kolmogorov-Smirnov method the data was really generated by the Pareto distributions\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KS P-value: 2.0794160126346703e-12\n",
            "According to Kolmogorov-Smirnov method the data was not generated by the Pareto distributions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooBbWrMyKB87"
      },
      "source": [
        "Last run result:\n",
        "\n",
        "KS P-value: 2.0794160126346703e-12\n",
        "\n",
        "According to Kolmogorov-Smirnov method the data was not generated by the Pareto distributions"
      ]
    }
  ]
}